/* 
 * GenericTreeMulticast.mac : part of the Mace toolkit for building distributed systems
 * 
 * Copyright (c) 2011, Charles Killian, James W. Anderson, John Fisher-Ogden, Ryan Braud
 * All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 * 
 *    * Redistributions of source code must retain the above copyright
 *      notice, this list of conditions and the following disclaimer.
 *    * Redistributions in binary form must reproduce the above copyright
 *      notice, this list of conditions and the following disclaimer in the
 *      documentation and/or other materials provided with the distribution.
 *    * Neither the names of the contributors, nor their associated universities 
 *      or organizations may be used to endorse or promote products derived from
 *      this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
 * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 * 
 * ----END-OF-LEGAL-STUFF---- */
#include "lib/NodeCollection.h"
#include "GlobalCommit.h"
#include "ThreadStructure.h"

using mace::NodeCollection;
using Log::endl;
service GenericTreeMulticast;

provides HierarchicalMulticast, Multicast, DeferredHierarchicalMulticast, DeferredMulticast;

// trace=off;
trace=med;
locking=read;

constants {
  int COMM_TYPE_MULTICAST = 0;
  int COMM_TYPE_ANYCAST = 1;
  int COMM_TYPE_DISTRIBUTE = 2;
  int COMM_TYPE_COLLECT = 3;
}

services {
  //Route data_ = RouteTransportWrapper();
  //Route data_ = DeferredRouteTransportWrapper();

  //NOTE: tree_ and data_ MUST use the same address scheme.  So if this runs over Scribe, 
  //the route service must be a service using either Pastry or Scribe's addressing scheme.

//  Route data_ = auto(shared, [], [RouteTransportWrapper]);
  Route data_ = auto(shared, [], [DeferredRouteTransportWrapper]);
  Tree tree_ = auto(shared, [], []);
}

auto_types {
  coloredNode __attribute((node())) {
    int color;              //0-white, 1-grey, 2-black
    int position;           //position added to.
  }
}

typedefs {
  typedef NodeCollection<coloredNode> visited;
  typedef int comm_type_t;
  typedef mace::map<MaceKey, int> KeyUidMap;
}

messages {
  anycast_data {
    MaceKey groupId; 
    MaceKey fromAddr;
    registration_uid_t regId;
    visited dfsState;
    mace::string payload __attribute((dump(no)));
  }
  data {
    MaceKey groupId; 
    MaceKey fromAddr;
    comm_type_t commType;
    registration_uid_t regId;
    int uid;
    mace::string payload __attribute((dump(no)));
  }
}

states {
  initDone;
}

state_variables {
  MaceKey me; //XXX: As `me' cannot change, it could ideally be marked "const" in some fashion and avoid snapshotting.
  registration_uid_t authoritativeJoinHandler; //This should go away with the method remappings.
  //XXX send and recv uid technically need exclusive access...
  int sendUid = 1;
  KeyUidMap recvUid;
}

transitions {

  //NOTE: maceInit() is a locking transition by definition.  User cannot override this.
  downcall (state == init) maceInit() {
    authoritativeJoinHandler = -1;
    me = localAddress();
    state = initDone;
  }

  downcall anycast(const MaceKey& dest, const mace::string& s, 
                   registration_uid_t regId) {
    // XXX BROKEN
    static const visited vnull = visited();
    return downcall_route(me, anycast_data(dest, me, 
                                           regId, vnull, s));
  }
    
  downcall multicast(const MaceKey& dest, const mace::string& s, 
                     registration_uid_t regId) [locking=none] {

    //XXX sendUid is a case where individual fine-grained locking may be warranted.  In this toy app, only one thread calls multicast, which means only one thread modifies sendUid, so it's "safe".
    // yoo : set it to locking=off.
    defer_multicastData(me, me, dest, s, COMM_TYPE_MULTICAST, regId, sendUid++);
    return true;
  }

  downcall collect(const MaceKey& dest, const mace::string& s, 
                   registration_uid_t regId) [locking=none] {
    MaceKey nexthop = (downcall_isRoot(dest) ? me : downcall_getParent(dest));
    // The forward handler will take care of upcall forward -- which in 
    // turn will deliver if needed

    data msg(dest, me, COMM_TYPE_COLLECT, regId, sendUid++, s);

    if (upcall_forward(msg.fromAddr, msg.groupId, nexthop, msg.payload, msg.regId)) {
      return downcall_route(nexthop, msg);
    }
    return true;
  }

  downcall distribute(const MaceKey& dest, const mace::string& s, 
                      registration_uid_t regId) [locking=none] {

    defer_multicastData(me, me, dest, s, COMM_TYPE_DISTRIBUTE, regId, sendUid++);
    return true;
    //     return downcall_route(me, data(dest, me, 
    //                                    COMM_TYPE_DISTRIBUTE, regId, sendUid++, s));
  }

//   (state == initDone) {
//     downcall multicast(const MaceKey& dest, const mace::string& s, registration_uid_t rid) {
//       maceout << "delivering " << dest << " " << s << " to " << rid << Log::endl;
//       upcall_deliver(me, dest, s, rid);
//       return true;
//     }
//   }

  upcall (dest == me || (nextHop == me && dest == msg.groupId))
    forward(const MaceKey& from, const MaceKey& dest, MaceKey& nextHop, 
            const anycast_data& msg) {
//    const MaceKey& me = me();
    visited dfsState = msg.dfsState;
    //Step 1: If I am a "white" node (first time), add my children
    if(!dfsState.contains(me) || dfsState.get(me).color == 0) {
      if(!dfsState.contains(me)) {
        dfsState.add(me).position = dfsState.size();
      }
      dfsState.get(me).color = 1;
      const NodeSet& children = downcall_getChildren(msg.groupId);
      for(NodeSet::const_iterator i = children.begin(); i != children.end(); i++) {
        if(!dfsState.contains(*i)) {
          dfsState.add(*i).position = dfsState.size();
        }
      }
    }

    //Step 1.5: Sort the nodes
    std::set<coloredNode, comparePosition> sorted(dfsState.setBegin(), 
                                                  dfsState.setEnd());

    //Set 2: Pick the next node in line to process the msg.
    for(std::set<coloredNode, comparePosition>::iterator i = sorted.begin(); 
        i != sorted.end(); i++) {
      const coloredNode& node = *i;
      if(node.color != 2 && node.getId() == me && from == me) { //If I sent the message, don't bother calling forward.  (Is that right?)
        dfsState.get(me).color = 2;
      }
      else if((node).color != 2) {
        if(node.getId() ==me) {
          dfsState.get(me).color = 2;
          //Visit this node.
          maceout << "All children visited.  Visiting this node. " << 
                  "(anycast msg from " << from << " (orig from " 
                  << msg.fromAddr << ") for group " << msg.groupId
                  << ")" << Log::endl;
          MaceKey nexthop = MaceKey::null; //XXX Should this be something different?
          if(!upcall_forward(msg.fromAddr, msg.groupId, nexthop, 
                msg.payload, msg.regId)) {
            return false;
          }
        } else {
          maceout << "Forwarding anycast msg from " << from
                  << " (orig from " << msg.fromAddr << ") for group "
                  << msg.groupId<< " to child "<< node << Log::endl;
          bool accepted = downcall_route(node.getId(), anycast_data(msg.groupId, msg.fromAddr, msg.regId, dfsState, msg.payload));
          if(accepted) {
            maceout << "Forward successful" << Log::endl;
          } else {
            macewarn << "Forward rejected" << Log::endl;
          }
          return false;
        }
      }
    }

    //Step 3: Route to parent, if any
    //NOTE: dfsState is either all black, or empty
    const MaceKey& parent = downcall_getParent(msg.groupId);
    if(!parent.isNullAddress() && parent != me && parent != dest) {
      maceout << "Forwarding to parent " << parent << " anycast msg from " 
              << from << " (orig from " << msg.fromAddr << ") for group " 
              << msg.groupId<<Log::endl;
      downcall_route(parent, anycast_data(msg.groupId, 
                                          msg.fromAddr, 
                                          msg.regId, 
                                          dfsState, msg.payload));
      return false;
    }
    return true;
  }

  //state == joined && 
  //COMM_TYPE_COLLECT && 
  //children.contains(from) && 
//  upcall (msg.commType == COMM_TYPE_COLLECT 
//            && downcall_getChildren(msg.groupId).contains(from)) 
  upcall (msg.commType == COMM_TYPE_COLLECT) 
    forward(const MaceKey& from, const MaceKey& dest, 
            MaceKey& nexthop, const data& msg)  {

    nexthop = downcall_getParent(msg.groupId);
    return upcall_forward(msg.fromAddr, msg.groupId, nexthop, 
                          msg.payload, msg.regId);
  }

  //   upcall (msg.commType == COMM_TYPE_COLLECT && (downcall_getChildren(msg.groupId).contains(from) || (from == me /*&& downcall_getParent(msg.groupId) == me*/)) ) 
  upcall (msg.commType == COMM_TYPE_COLLECT) 
            deliver(const MaceKey& from, const MaceKey& dest, const data& msg)  {
    // shyoo: this is deferrable.
    upcall_deliver(msg.fromAddr, msg.groupId, msg.payload, msg.regId);
  }

  //state == joined && 
  //dest == me &&
  //!COMM_TYPE_COLLECT && 
  //COMM_TYPE_DISTRIBUTE => parent == from || from == me
  upcall (nextHop == me &&
            (msg.commType != COMM_TYPE_COLLECT) &&
            (msg.commType != COMM_TYPE_DISTRIBUTE || downcall_getParent(msg.groupId) == from || from == me))
            forward(const MaceKey& from, const MaceKey& dest, MaceKey& nextHop, const data& msg)  {
    MaceKey nexthop = msg.groupId;
    const int& highestUid = recvUid[msg.fromAddr];
    //     macedbg(1) << "Message from " << msg.fromAddr << " with uid " << msg.uid << " highestUid " << highestUid << endl;
    if (msg.uid <= highestUid) { 
      macewarn << "Old message " << msg.uid << " seen from " << msg.fromAddr << " highestUid was " << highestUid << endl;
      return false;
    }
    return upcall_forward(msg.fromAddr, msg.groupId, nexthop, msg.payload, msg.regId);
  }

  //omit: dest == me &&
  upcall ((msg.commType != COMM_TYPE_COLLECT) &&
            (msg.commType != COMM_TYPE_DISTRIBUTE || downcall_getParent(msg.groupId) == from || from == me))
            deliver(const MaceKey& from, const MaceKey& dest, 
                    const data& msg) {

    if(from == me) { maceerr << "Message " << msg << " is from me?!?" << endl; }
    else {
      multicastData(from, msg.fromAddr, msg.groupId, msg.payload, msg.commType, msg.regId, msg.uid);
    }

//     upcall_deliver(msg.fromAddr, msg.groupId, msg.payload, msg.commType, msg.regId);
//     if(!parent.isNullAddress() && (msg.commType == COMM_TYPE_MULTICAST && from != parent)) {
//       downcall_routeDirect(parent, msg);
//     }
//     for(NodeSet::iterator i = children.begin(); i != children.end(); i++) {
//       if(from != *i) {
//         downcall_routeDirect(*i, msg);
//       }
//     }
  }

  upcall deliver(const MaceKey& source, const MaceKey& dest, const anycast_data& msg) {
    macewarn << "Received erroneous anycast message: " << msg << Log::endl;
    // shyoo: this is deferrable.
    upcall_deliver(msg.fromAddr, msg.groupId, msg.payload, msg.regId);
  }

  upcall deliver(const MaceKey& source, const MaceKey& dest, const data& msg)  {
    maceerr << "Received erroneous data message: " << msg << Log::endl;
    maceout << "State " << getStateName(state) << " parent " << downcall_getParent(msg.groupId) << " from " << source << " me " << me << " dest " << dest << endl;
  }
}

routines {
  class comparePosition {
  public:
    bool operator()(const coloredNode& one, const coloredNode& two) const { 
      if(one.color != two.color) { return one.color < two.color; }
      return one.position < two.position; 
    }
  };

  bool multicastData(const MaceKey& from, const MaceKey& msgFromAddr, 
                     const MaceKey& groupId, const mace::string& payload, 
                     comm_type_t commType, registration_uid_t regId, int uid) {

    maceout << "Multicasting from " << from << " on group " << groupId << " data of size " << payload.size() << " uid " << uid << endl;
    //XXX: need exclusivity technically.  Might see a segfault due to this...
    recvUid[msgFromAddr] = uid;
    // shyoo: this is deferrable
    upcall_deliver(msgFromAddr, groupId, payload, regId);
    const MaceKey& parent = downcall_getParent(groupId);
    maceout << "Parent for group " << groupId << " is " << parent << endl;
    bool success = true;
    if(!parent.isNullAddress() && parent != me &&
       (commType == COMM_TYPE_MULTICAST && from != parent)) {
      success = downcall_route(parent, data(groupId, msgFromAddr, commType, regId, uid, payload)) && success;
    }
    const NodeSet& children = downcall_getChildren(groupId);
    maceout << "Children for group " << groupId << " are " << children << endl;
    for(NodeSet::const_iterator i = children.begin(); i != children.end(); i++) {
      if(from != *i) {
        success = downcall_route(*i, data(groupId, msgFromAddr, commType, regId, uid, payload)) && success;
      }
    }
    return success;
  }
}
